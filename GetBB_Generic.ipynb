{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/matthewgilbert/pdblp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'CompositeDef.csv' does not exist: b'CompositeDef.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8504c47b3929>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mUniverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CompositeDef.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mUniverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'UniverseStrategyTS.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mUniverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EQSecurityMaster.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Universe = pd.read_csv('Competitors.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython\\python-3.5.4.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython\\python-3.5.4.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython\\python-3.5.4.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython\\python-3.5.4.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\winpython\\python-3.5.4.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'CompositeDef.csv' does not exist: b'CompositeDef.csv'"
     ]
    }
   ],
   "source": [
    "Universe = pd.read_csv('CompositeDef.csv')\n",
    "Universe = pd.read_csv('UniverseStrategyTS.csv')\n",
    "Universe = pd.read_csv('EQSecurityMaster.csv')\n",
    "#Universe = pd.read_csv('Competitors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Universe.Tickers[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[np.isnan(t) for t in Universe.Tickers]\n",
    "Tickers = Universe.Tickers\n",
    "iVal = [type(t)==str for t in Tickers]\n",
    "Tickers = Tickers[iVal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r'Equity')\n",
    "\n",
    "\n",
    "#Tickers = Universe.Tickers[~Universe.CheckBB]\n",
    "#Tickers = Tickers.unique()\n",
    "Tickers = [t for t in Tickers if pat.search(t)]\n",
    "Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdblp\n",
    "con = pdblp.BCon(debug=False, port=8194, timeout=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdblpext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tickers = np.array([\"ENRFCL 1GQ Index\", \"CFWDCL 1GQ Index\"])\n",
    "Tickers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "iValid = np.full((len(Tickers)), False)\n",
    "\n",
    "for iT, iTicker in enumerate(Tickers):\n",
    "    try:\n",
    "        n = con.ref(iTicker, \"NAME\")\n",
    "        iValid[iT] = True\n",
    "    except:\n",
    "        print(iT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>field</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFWDCL 1GQ Index</td>\n",
       "      <td>NAME</td>\n",
       "      <td>New York Mercantile Exchange/W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ticker field                           value\n",
       "0  CFWDCL 1GQ Index  NAME  New York Mercantile Exchange/W"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iValid\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tickers = Tickers[iValid]\n",
    "oTickers = Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tickers = list()\n",
    "for f in ['EQTSCUR_MKT_CAP{}.pkl'.format(i) for i in np.arange(0,69)]:\n",
    "    d = pd.read_pickle(f)\n",
    "    Tickers = Tickers + d.columns.droplevel(1).tolist()\n",
    "\n",
    "    \n",
    "len(Tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENRFCL 1GQ Index ['PX_LAST', 'BN_SURVEY_AVERAGE', 'BN_SURVEY_LOW', 'BN_SURVEY_HIGH'] 20190724 20080101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>BN_SURVEY_AVERAGE</th>\n",
       "      <th>BN_SURVEY_LOW</th>\n",
       "      <th>BN_SURVEY_HIGH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>80.00</td>\n",
       "      <td>78.77</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>80.00</td>\n",
       "      <td>78.31</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-09</th>\n",
       "      <td>80.00</td>\n",
       "      <td>79.77</td>\n",
       "      <td>65.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-10</th>\n",
       "      <td>80.00</td>\n",
       "      <td>78.31</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-11</th>\n",
       "      <td>80.00</td>\n",
       "      <td>79.47</td>\n",
       "      <td>65.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-14</th>\n",
       "      <td>80.00</td>\n",
       "      <td>79.47</td>\n",
       "      <td>65.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-15</th>\n",
       "      <td>80.00</td>\n",
       "      <td>80.14</td>\n",
       "      <td>65.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-16</th>\n",
       "      <td>80.00</td>\n",
       "      <td>79.68</td>\n",
       "      <td>65.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-17</th>\n",
       "      <td>80.00</td>\n",
       "      <td>80.33</td>\n",
       "      <td>65.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-18</th>\n",
       "      <td>80.00</td>\n",
       "      <td>80.33</td>\n",
       "      <td>65.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-28</th>\n",
       "      <td>80.00</td>\n",
       "      <td>80.33</td>\n",
       "      <td>65.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-30</th>\n",
       "      <td>80.00</td>\n",
       "      <td>80.65</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-01</th>\n",
       "      <td>84.00</td>\n",
       "      <td>82.12</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-05</th>\n",
       "      <td>83.00</td>\n",
       "      <td>81.32</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-06</th>\n",
       "      <td>81.50</td>\n",
       "      <td>81.08</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-07</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-08</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-12</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-13</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-15</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-18</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-19</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-20</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-22</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-27</th>\n",
       "      <td>83.73</td>\n",
       "      <td>81.47</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-28</th>\n",
       "      <td>85.50</td>\n",
       "      <td>84.82</td>\n",
       "      <td>70.00</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-29</th>\n",
       "      <td>86.00</td>\n",
       "      <td>83.38</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-03</th>\n",
       "      <td>87.90</td>\n",
       "      <td>86.66</td>\n",
       "      <td>70.00</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-07</th>\n",
       "      <td>86.00</td>\n",
       "      <td>83.38</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-11</th>\n",
       "      <td>88.50</td>\n",
       "      <td>85.14</td>\n",
       "      <td>60.00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-23</th>\n",
       "      <td>60.50</td>\n",
       "      <td>60.82</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-27</th>\n",
       "      <td>60.50</td>\n",
       "      <td>60.82</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-28</th>\n",
       "      <td>60.50</td>\n",
       "      <td>60.82</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-29</th>\n",
       "      <td>60.50</td>\n",
       "      <td>60.82</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-30</th>\n",
       "      <td>60.50</td>\n",
       "      <td>60.82</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03</th>\n",
       "      <td>60.00</td>\n",
       "      <td>60.64</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-04</th>\n",
       "      <td>60.00</td>\n",
       "      <td>60.64</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-05</th>\n",
       "      <td>60.50</td>\n",
       "      <td>60.73</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-06</th>\n",
       "      <td>60.00</td>\n",
       "      <td>60.16</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-07</th>\n",
       "      <td>60.00</td>\n",
       "      <td>60.28</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-10</th>\n",
       "      <td>60.00</td>\n",
       "      <td>60.58</td>\n",
       "      <td>49.70</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-11</th>\n",
       "      <td>60.10</td>\n",
       "      <td>60.99</td>\n",
       "      <td>51.50</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12</th>\n",
       "      <td>60.05</td>\n",
       "      <td>60.68</td>\n",
       "      <td>51.50</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-14</th>\n",
       "      <td>60.05</td>\n",
       "      <td>60.45</td>\n",
       "      <td>51.50</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-17</th>\n",
       "      <td>60.10</td>\n",
       "      <td>60.47</td>\n",
       "      <td>51.50</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24</th>\n",
       "      <td>60.10</td>\n",
       "      <td>60.47</td>\n",
       "      <td>51.50</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25</th>\n",
       "      <td>60.10</td>\n",
       "      <td>60.47</td>\n",
       "      <td>51.50</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-27</th>\n",
       "      <td>60.37</td>\n",
       "      <td>60.53</td>\n",
       "      <td>51.50</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>62.00</td>\n",
       "      <td>61.36</td>\n",
       "      <td>52.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-02</th>\n",
       "      <td>62.00</td>\n",
       "      <td>61.36</td>\n",
       "      <td>52.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>62.00</td>\n",
       "      <td>61.36</td>\n",
       "      <td>52.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05</th>\n",
       "      <td>62.00</td>\n",
       "      <td>61.58</td>\n",
       "      <td>52.93</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-09</th>\n",
       "      <td>61.50</td>\n",
       "      <td>61.51</td>\n",
       "      <td>52.93</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-12</th>\n",
       "      <td>62.00</td>\n",
       "      <td>61.88</td>\n",
       "      <td>54.20</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-16</th>\n",
       "      <td>61.50</td>\n",
       "      <td>61.65</td>\n",
       "      <td>54.20</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-17</th>\n",
       "      <td>62.00</td>\n",
       "      <td>61.80</td>\n",
       "      <td>54.20</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-18</th>\n",
       "      <td>61.00</td>\n",
       "      <td>61.51</td>\n",
       "      <td>54.20</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-19</th>\n",
       "      <td>61.00</td>\n",
       "      <td>61.51</td>\n",
       "      <td>54.20</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-22</th>\n",
       "      <td>60.50</td>\n",
       "      <td>61.45</td>\n",
       "      <td>54.20</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-23</th>\n",
       "      <td>61.00</td>\n",
       "      <td>61.68</td>\n",
       "      <td>54.20</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1886 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PX_LAST  BN_SURVEY_AVERAGE  BN_SURVEY_LOW  BN_SURVEY_HIGH\n",
       "date                                                                 \n",
       "2008-01-03    80.00              78.77          60.00            95.0\n",
       "2008-01-07    80.00              78.31          60.00            95.0\n",
       "2008-01-09    80.00              79.77          65.00            95.0\n",
       "2008-01-10    80.00              78.31          60.00            95.0\n",
       "2008-01-11    80.00              79.47          65.00            95.0\n",
       "2008-01-14    80.00              79.47          65.00            95.0\n",
       "2008-01-15    80.00              80.14          65.00            95.0\n",
       "2008-01-16    80.00              79.68          65.00            95.0\n",
       "2008-01-17    80.00              80.33          65.00            95.0\n",
       "2008-01-18    80.00              80.33          65.00            95.0\n",
       "2008-01-28    80.00              80.33          65.00            95.0\n",
       "2008-01-30    80.00              80.65          60.00            95.0\n",
       "2008-02-01    84.00              82.12          60.00            95.0\n",
       "2008-02-05    83.00              81.32          60.00            95.0\n",
       "2008-02-06    81.50              81.08          60.00            95.0\n",
       "2008-02-07    83.73              81.47          60.00            95.0\n",
       "2008-02-08    83.73              81.47          60.00            95.0\n",
       "2008-02-12    83.73              81.47          60.00            95.0\n",
       "2008-02-13    83.73              81.47          60.00            95.0\n",
       "2008-02-15    83.73              81.47          60.00            95.0\n",
       "2008-02-18    83.73              81.47          60.00            95.0\n",
       "2008-02-19    83.73              81.47          60.00            95.0\n",
       "2008-02-20    83.73              81.47          60.00            95.0\n",
       "2008-02-22    83.73              81.47          60.00            95.0\n",
       "2008-02-27    83.73              81.47          60.00            95.0\n",
       "2008-02-28    85.50              84.82          70.00            98.0\n",
       "2008-02-29    86.00              83.38          60.00            95.0\n",
       "2008-03-03    87.90              86.66          70.00            98.0\n",
       "2008-03-07    86.00              83.38          60.00            95.0\n",
       "2008-03-11    88.50              85.14          60.00            95.0\n",
       "...             ...                ...            ...             ...\n",
       "2019-05-23    60.50              60.82          49.70            70.8\n",
       "2019-05-27    60.50              60.82          49.70            70.8\n",
       "2019-05-28    60.50              60.82          49.70            70.8\n",
       "2019-05-29    60.50              60.82          49.70            70.8\n",
       "2019-05-30    60.50              60.82          49.70            70.8\n",
       "2019-06-03    60.00              60.64          49.70            70.8\n",
       "2019-06-04    60.00              60.64          49.70            70.8\n",
       "2019-06-05    60.50              60.73          49.70            70.8\n",
       "2019-06-06    60.00              60.16          49.70            70.8\n",
       "2019-06-07    60.00              60.28          49.70            70.8\n",
       "2019-06-10    60.00              60.58          49.70            70.8\n",
       "2019-06-11    60.10              60.99          51.50            70.8\n",
       "2019-06-12    60.05              60.68          51.50            70.8\n",
       "2019-06-14    60.05              60.45          51.50            70.8\n",
       "2019-06-17    60.10              60.47          51.50            70.8\n",
       "2019-06-24    60.10              60.47          51.50            70.8\n",
       "2019-06-25    60.10              60.47          51.50            70.8\n",
       "2019-06-27    60.37              60.53          51.50            70.8\n",
       "2019-07-01    62.00              61.36          52.00            70.0\n",
       "2019-07-02    62.00              61.36          52.00            70.0\n",
       "2019-07-03    62.00              61.36          52.00            70.0\n",
       "2019-07-05    62.00              61.58          52.93            70.0\n",
       "2019-07-09    61.50              61.51          52.93            70.0\n",
       "2019-07-12    62.00              61.88          54.20            70.0\n",
       "2019-07-16    61.50              61.65          54.20            70.0\n",
       "2019-07-17    62.00              61.80          54.20            70.0\n",
       "2019-07-18    61.00              61.51          54.20            70.0\n",
       "2019-07-19    61.00              61.51          54.20            70.0\n",
       "2019-07-22    60.50              61.45          54.20            70.0\n",
       "2019-07-23    61.00              61.68          54.20            70.0\n",
       "\n",
       "[1886 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "todate = (date.today() - timedelta(1)).strftime('%Y%m%d')\n",
    "fromdate = date(2000, 1, 1).strftime('%Y%m%d')\n",
    "fromdate = date(2008, 1, 1).strftime('%Y%m%d')\n",
    "fields = ['PX_LAST', 'BN_SURVEY_AVERAGE', 'BN_SURVEY_LOW', 'BN_SURVEY_HIGH']\n",
    "#fields = ['PX_LAST', \"\"\n",
    "elms = []\n",
    "Tickers = \"ENRFCL 1GQ Index\"\n",
    "#Tickers = \"SPX Index\"\n",
    "print(Tickers, fields, todate, fromdate)\n",
    "a = pd.DataFrame()\n",
    "for fld in fields:\n",
    "    a[fld] = con.bdh(Tickers, fld, fromdate, todate).iloc[:, 0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x178b54ec0f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ValueError('Length mismatch: Expected axis has 0 elements, new values have 4 elements',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\winpython\\python-3.5.4.amd64\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m(155)\u001b[0;36mset_axis\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    154 \u001b[1;33m                \u001b[1;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 155 \u001b[1;33m                'values have {new} elements'.format(old=old_len, new=new_len))\n",
      "\u001b[0m\u001b[1;32m    156 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  dir()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['axis', 'new_labels', 'new_len', 'old_len', 'self']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockManager\n",
      "Items: Index([], dtype='object')\n",
      "Axis 1: Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\winpython\\python-3.5.4.amd64\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m(638)\u001b[0;36m_set_axis\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    637 \u001b[1;33m    \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 638 \u001b[1;33m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    639 \u001b[1;33m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self._data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockManager\n",
      "Items: Index([], dtype='object')\n",
      "Axis 1: Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\dev\\arpeggioqi\\arpeggioone\\arpeggioone\\pandas\\_libs\\properties.pyx\u001b[0m(69)\u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  dir()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AxisProperty', 'CachedProperty', '__builtins__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__pyx_unpickle_AxisProperty', '__pyx_unpickle_CachedProperty', '__spec__', '__test__', 'cache_readonly']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "with ipdb.launch_ipdb_on_exception():\n",
    "    con.bdh(\"ENRFCL 1GQ Index\", \"PX_LAST\", fromdate, todate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "todate = (date.today() - timedelta(1)).strftime('%Y%m%d')\n",
    "fromdate = date(2000, 1, 1).strftime('%Y%m%d')\n",
    "fields = {'PX_LAST', 'TOT_RETURN_INDEX_NET_DVDS', 'PX_VOLUME'}\n",
    "elms = []\n",
    "\n",
    "todate = date(2018, 6, 30).strftime('%Y%m%d')\n",
    "fromdate = date(1999, 12, 31).strftime('%Y%m%d')\n",
    "fields = {'CUR_MKT_CAP'}\n",
    "elms = [(\"periodicitySelection\", \"MONTHLY\")]\n",
    "\n",
    "\n",
    "todate = (date.today() - timedelta(1)).strftime('%Y%m%d')\n",
    "fromdate = date(2000, 1, 1).strftime('%Y%m%d')\n",
    "fields = {'TOT_RETURN_INDEX_NET_DVDS'}\n",
    "elms = []\n",
    "\n",
    "\n",
    "todate = date(2018, 6, 30).strftime('%Y%m%d')\n",
    "fromdate = date(1999, 12, 31).strftime('%Y%m%d')\n",
    "elms = [(\"periodicitySelection\", \"QUARTERLY\")]\n",
    "fields = ['FISCAL_YEAR_PERIOD',\n",
    "    'ANNOUNCEMENT_DT',\n",
    "    'LATEST_PERIOD_END_DT_FULL_RECORD',\n",
    "    'BOOK_VAL_PER_SH',\n",
    "    'TRAIL_12M_EPS',\n",
    "    'BEST_EPS',\n",
    "    'EV_TO_T12M_EBITDA',\n",
    "    'EQY_DVD_YLD_IND_NET']\n",
    "\n",
    "\n",
    "cTickers = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tickers = list(Tickers)\n",
    "#Tickers = Tickers.tolist()\n",
    "bTickers = [Tickers[i:i + cTickers] for i in range(0, len(Tickers), cTickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sTickers = bTickers;\n",
    "for iSet, iTickers in enumerate(bTickers):\n",
    "    \n",
    "    for field in fields:\n",
    "        try:\n",
    "            sTickers[iSet] = con.bdh(iTickers, field, fromdate, todate, elms)\n",
    "            sTickers[iSet].to_pickle('./FACTORS{}{}.pkl'.format(field, iSet))\n",
    "            \n",
    "        except:\n",
    "            print(\"failed\")\n",
    "        finally:\n",
    "            print(iSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iB in sTickers:\n",
    "    if isinstance(iB.columns, pd.core.indexes.multi.MultiIndex):\n",
    "        iB.columns = iB.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sTickers = 32*[None]\n",
    "for iB in range(0, 32):\n",
    "    sTickers[iB] = pd.read_pickle('./{}.pkl'.format(iB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.concat(sTickers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.columns = r.columns.droplevel(1)\n",
    "y.columns = y.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\".*Equity.*\")\n",
    "\n",
    "iCol = [i for i in r.columns if not regex.match(i)]\n",
    "\n",
    "\n",
    "r = r.loc[:, iCol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.columns.shape)\n",
    "print(r.columns.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.concat([r, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xy.columns.shape)\n",
    "print(Xy.columns.unique().shape)\n",
    "print(r.columns.shape)\n",
    "print(r.columns.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.to_pickle('all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.read_pickle('all.pkl')\n",
    "\n",
    "Xy.loc[:, 'QSPNX US Equity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnan_leading(x):\n",
    "#    return range(1, x.shape[0]+1) * x.notnull() == 0\n",
    "\n",
    "    return x.ffill().isnull() | x.bfill().isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove before y\n",
    "iVal = ~isnan_leading(Xy)\n",
    "Xy = Xy.iloc[iVal.iloc[:, -1].as_matrix(), :]\n",
    "\n",
    "# remove dates with too little obs\n",
    "iDVal = Xy.notnull().sum(axis=1)>20\n",
    "Xy = Xy.iloc[iDVal.as_matrix(), :]\n",
    "\n",
    "# remove x with too little obs\n",
    "iXVal = Xy.notnull().sum(axis=0)>1000\n",
    "Xy = Xy.iloc[:, iXVal.as_matrix()]\n",
    "\n",
    "# remove x with negative values since that is not a TRI\n",
    "iXVal = (Xy.fillna(1)>0).all(axis=0)\n",
    "Xy = Xy.iloc[:, iXVal.as_matrix()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show missing\n",
    "Xy.notnull().sum(axis=1).plot()\n",
    "plt.show()\n",
    "\n",
    "Xy.notnull().sum(axis=0).hist(bins=40)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(Xy.notnull().as_matrix())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna\n",
    "iVal = Xy.bfill().isnull()\n",
    "Xy = Xy.ffill()\n",
    "Xy.iloc[iVal] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc ret\n",
    "TRI = Xy\n",
    "RET = (TRI/TRI.shift(1)-1).fillna(0)\n",
    "RET5 = RET.rolling(5).sum().iloc[5:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vol = RET5.std()*np.sqrt(250)\n",
    "Vol.sort_values().plot()\n",
    "plt.show()\n",
    "\n",
    "Vol.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.loc[:, \"VIX Index\"].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RET = RET / Vol * 0.1\n",
    "RET5 = RET5 / Vol * 0.1\n",
    "TRI = (1+RET).cumprod()-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import nnls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0 = np.ones(RET5.shape[1])/RET5.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = RET5.iloc[:, :-1].as_matrix()\n",
    "y5 = RET5.iloc[:, -1].as_matrix()\n",
    "\n",
    "b, r = nnls(X5, y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RET.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(b)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = RET.iloc[:, :-1].dot(b)\n",
    "y = RET.iloc[:, -1]\n",
    "pd.concat([y, yhat], axis=1).cumsum(axis=0).plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back fill history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_ = pd.read_pickle('./all.pkl')\n",
    "\n",
    "Xy_ = Xy_.loc[:, RET.columns.tolist()]\n",
    "\n",
    "print(Xy_.shape)\n",
    "print(b.shape)\n",
    "print(RET.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_ = Xy_.ffill()\n",
    "\n",
    "RET_ = Xy_/Xy_.shift(1)-1\n",
    "RET_ = RET_ / Vol * 0.1\n",
    "\n",
    "yhat_ = RET_.iloc[:, :-1].fillna(0).dot(b)\n",
    "obs_ = RET_.iloc[:, :-1].notnull().dot(b)\n",
    "y_ = RET_.iloc[:, -1]\n",
    "\n",
    "\n",
    "obs_.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.concat([y, yhat_, obs_], axis=1)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.iloc[4500:, :2].cumsum(axis=0).plot()\n",
    "plt.show()\n",
    "\n",
    "Y.iloc[:, 1].cumsum(axis=0).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def GetDataSets():\n",
    "    file_names = os.listdir('./parts/')\n",
    "    filesets = set([re.sub('[0-9]+\\.pkl', '', fn) for fn in file_names])\n",
    "    filesets = list(filesets)\n",
    "    return filesets\n",
    "\n",
    "\n",
    "filesets = GetDataSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineParts(fileset):\n",
    "    pat = '{}[0-9]+\\.pkl'.format(fileset)\n",
    "\n",
    "    files = [fn for fn in os.listdir('./parts/') if re.match(pat, fn)]\n",
    "    len(files)\n",
    "    \n",
    "    parts = []\n",
    "    for file in files:\n",
    "        part = pd.read_pickle('./parts/' + file)\n",
    "        parts.append(part)\n",
    "        \n",
    "    parts = pd.concat(parts, axis=1)\n",
    "    parts.to_pickle('./{}.pkl'.format(fileset))\n",
    "    \n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fs in filesets:\n",
    "    CombineParts(fs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "parts['.MLREGEF Index'].plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts.iloc[:, 0:5].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parts.loc[:, ('.MLREGEF Index', 'PX_LAST')].ffill().bfill().plot()\n",
    "parts.loc[:, '.MLREGEF Index'].ffill().bfill().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = parts.loc[:, '.MLREGEF Index']\n",
    "\n",
    "s = s[(~s.isnull()).as_matrix()]\n",
    "\n",
    "s.iloc[3] - s.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = parts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(c.levels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_pickle('AssetTS.pkl')\n",
    "RP = pd.read_pickle('RP.pkl')\n",
    "C = pd.concat([A, RP], axis=1)\n",
    "C.to_pickle('NonEQTS.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(C)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.isnull().sum().sort_values().plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataSetsInDir(FileDir = './parts/'):\n",
    "    print(FileDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pdblpext import PDBLPext\n",
    "\n",
    "import pdblpext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = PDBLPext(['asdf', 'dddd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.GetTickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.cBatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.Test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
